{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función sigmoide y su derivada\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_error(y_true, y_pred):\n",
    "     return np.mean(y_true - y_pred)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred + 1e-9))\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_size, output_size):\n",
    "    weights = np.random.randn(input_size, output_size) * 0.01\n",
    "    bias = np.zeros((1, output_size))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, weights, bias):\n",
    "    z = np.dot(X, weights) + bias\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, y, output, weights, bias, learning_rate):\n",
    "    # Calcular el error\n",
    "    error = output - y\n",
    "    \n",
    "    # Calcular los gradientes\n",
    "    d_weights = np.dot(X.T, error * sigmoid_derivative(output))\n",
    "    d_bias = np.sum(error * sigmoid_derivative(output), axis=0, keepdims=True)\n",
    "    \n",
    "    # Actualizar pesos y sesgos\n",
    "    weights -= learning_rate * d_weights\n",
    "    bias -= learning_rate * d_bias\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, input_size, output_size, epochs, learning_rate):\n",
    "    # Inicializar pesos y sesgos\n",
    "    weights, bias = initialize_weights(input_size, output_size)\n",
    "    \n",
    "    # Entrenar por varias épocas\n",
    "    for epoch in range(epochs):\n",
    "        # Propagación hacia adelante\n",
    "        output = forward_pass(X, weights, bias)\n",
    "        \n",
    "        # Calcular pérdida\n",
    "        # loss = binary_crossentropy(y, output)\n",
    "        loss = linear_error(y, output)\n",
    "        \n",
    "        # Retropropagación\n",
    "        weights, bias = backpropagation(X, y, output, weights, bias, learning_rate)\n",
    "        \n",
    "        # Imprimir el progreso cada 100 épocas\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción\n",
    "def predict(X, weights, bias):\n",
    "    output = forward_pass(X, weights, bias)\n",
    "    # return (output > 0.3).astype(int)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = ([precio,metroscuadrados,pisomarmol,pisomadera,hornoagas,hornoelectrico])\n",
    "#y = ([moderna,rustica,barata])\n",
    "\n",
    "# X = np.array([\n",
    "#     [150000, 120, 1, 0, 1, 0],\n",
    "#     [80000, 80, 0, 1, 0, 1],\n",
    "#     [200000, 150, 1, 1, 1, 1],\n",
    "#     [50000, 60, 0, 0, 0, 1],\n",
    "#     [120000, 100, 1, 0, 1, 0]\n",
    "# ])\n",
    "\n",
    "\n",
    "# y = np.array([\n",
    "#     [1, 0, 0],\n",
    "#     [0, 1, 1],\n",
    "#     [1, 0, 0],\n",
    "#     [0, 1, 1],\n",
    "#     [1, 0, 0] \n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle Model</th>\n",
       "      <th>Battery Capacity (kWh)</th>\n",
       "      <th>Energy Consumed (kWh)</th>\n",
       "      <th>Charging Duration (hours)</th>\n",
       "      <th>Charging Rate (kW)</th>\n",
       "      <th>Charging Cost (USD)</th>\n",
       "      <th>State of Charge (Start %)</th>\n",
       "      <th>State of Charge (End %)</th>\n",
       "      <th>Distance Driven (since last charge) (km)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Vehicle Age (years)</th>\n",
       "      <th>User Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW i3</td>\n",
       "      <td>108.463007</td>\n",
       "      <td>60.712346</td>\n",
       "      <td>0.591363</td>\n",
       "      <td>36.389181</td>\n",
       "      <td>13.087717</td>\n",
       "      <td>29.371576</td>\n",
       "      <td>86.119962</td>\n",
       "      <td>293.602111</td>\n",
       "      <td>27.947953</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Commuter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Vehicle Model  Battery Capacity (kWh)  Energy Consumed (kWh)  \\\n",
       "0        BMW i3              108.463007              60.712346   \n",
       "\n",
       "   Charging Duration (hours)  Charging Rate (kW)  Charging Cost (USD)  \\\n",
       "0                   0.591363           36.389181            13.087717   \n",
       "\n",
       "   State of Charge (Start %)  State of Charge (End %)  \\\n",
       "0                  29.371576                86.119962   \n",
       "\n",
       "   Distance Driven (since last charge) (km)  Temperature (°C)  \\\n",
       "0                                293.602111         27.947953   \n",
       "\n",
       "   Vehicle Age (years) User Type  \n",
       "0                  2.0  Commuter  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"ev_charging_patterns.csv\")\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.drop(columns=['User ID', 'Charging Station ID', 'Charging Station Location','Charging Start Time','Charging End Time','Time of Day','Day of Week','Charger Type'])\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop('User Type', axis=1)\n",
    "X = pd.get_dummies(X, drop_first=False).astype(int).to_numpy()\n",
    "\n",
    "y = dataset['User Type']\n",
    "y= pd.get_dummies(y, drop_first=False).astype(int).to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = StandardScaler().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "input_size = X.shape[1]\n",
    "output_size = y.shape[1]\n",
    "epochs = 30000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -0.5000\n",
      "Epoch 100, Loss: -0.0964\n",
      "Epoch 200, Loss: -0.0809\n",
      "Epoch 300, Loss: -0.0742\n",
      "Epoch 400, Loss: -0.0698\n",
      "Epoch 500, Loss: -0.0668\n",
      "Epoch 600, Loss: -0.0647\n",
      "Epoch 700, Loss: -0.0631\n",
      "Epoch 800, Loss: -0.0619\n",
      "Epoch 900, Loss: -0.0610\n",
      "Epoch 1000, Loss: -0.0601\n",
      "Epoch 1100, Loss: -0.0593\n",
      "Epoch 1200, Loss: -0.0585\n",
      "Epoch 1300, Loss: -0.0577\n",
      "Epoch 1400, Loss: -0.0571\n",
      "Epoch 1500, Loss: -0.0564\n",
      "Epoch 1600, Loss: -0.0558\n",
      "Epoch 1700, Loss: -0.0553\n",
      "Epoch 1800, Loss: -0.0548\n",
      "Epoch 1900, Loss: -0.0544\n",
      "Epoch 2000, Loss: -0.0540\n",
      "Epoch 2100, Loss: -0.0536\n",
      "Epoch 2200, Loss: -0.0533\n",
      "Epoch 2300, Loss: -0.0530\n",
      "Epoch 2400, Loss: -0.0527\n",
      "Epoch 2500, Loss: -0.0525\n",
      "Epoch 2600, Loss: -0.0523\n",
      "Epoch 2700, Loss: -0.0521\n",
      "Epoch 2800, Loss: -0.0519\n",
      "Epoch 2900, Loss: -0.0517\n",
      "Epoch 3000, Loss: -0.0515\n",
      "Epoch 3100, Loss: -0.0513\n",
      "Epoch 3200, Loss: -0.0511\n",
      "Epoch 3300, Loss: -0.0509\n",
      "Epoch 3400, Loss: -0.0508\n",
      "Epoch 3500, Loss: -0.0506\n",
      "Epoch 3600, Loss: -0.0504\n",
      "Epoch 3700, Loss: -0.0503\n",
      "Epoch 3800, Loss: -0.0502\n",
      "Epoch 3900, Loss: -0.0500\n",
      "Epoch 4000, Loss: -0.0499\n",
      "Epoch 4100, Loss: -0.0498\n",
      "Epoch 4200, Loss: -0.0497\n",
      "Epoch 4300, Loss: -0.0496\n",
      "Epoch 4400, Loss: -0.0496\n",
      "Epoch 4500, Loss: -0.0495\n",
      "Epoch 4600, Loss: -0.0494\n",
      "Epoch 4700, Loss: -0.0494\n",
      "Epoch 4800, Loss: -0.0493\n",
      "Epoch 4900, Loss: -0.0493\n",
      "Epoch 5000, Loss: -0.0492\n",
      "Epoch 5100, Loss: -0.0492\n",
      "Epoch 5200, Loss: -0.0491\n",
      "Epoch 5300, Loss: -0.0491\n",
      "Epoch 5400, Loss: -0.0491\n",
      "Epoch 5500, Loss: -0.0490\n",
      "Epoch 5600, Loss: -0.0490\n",
      "Epoch 5700, Loss: -0.0490\n",
      "Epoch 5800, Loss: -0.0489\n",
      "Epoch 5900, Loss: -0.0489\n",
      "Epoch 6000, Loss: -0.0488\n",
      "Epoch 6100, Loss: -0.0488\n",
      "Epoch 6200, Loss: -0.0488\n",
      "Epoch 6300, Loss: -0.0487\n",
      "Epoch 6400, Loss: -0.0487\n",
      "Epoch 6500, Loss: -0.0486\n",
      "Epoch 6600, Loss: -0.0486\n",
      "Epoch 6700, Loss: -0.0486\n",
      "Epoch 6800, Loss: -0.0485\n",
      "Epoch 6900, Loss: -0.0485\n",
      "Epoch 7000, Loss: -0.0484\n",
      "Epoch 7100, Loss: -0.0484\n",
      "Epoch 7200, Loss: -0.0484\n",
      "Epoch 7300, Loss: -0.0483\n",
      "Epoch 7400, Loss: -0.0483\n",
      "Epoch 7500, Loss: -0.0483\n",
      "Epoch 7600, Loss: -0.0482\n",
      "Epoch 7700, Loss: -0.0482\n",
      "Epoch 7800, Loss: -0.0482\n",
      "Epoch 7900, Loss: -0.0482\n",
      "Epoch 8000, Loss: -0.0481\n",
      "Epoch 8100, Loss: -0.0481\n",
      "Epoch 8200, Loss: -0.0481\n",
      "Epoch 8300, Loss: -0.0481\n",
      "Epoch 8400, Loss: -0.0481\n",
      "Epoch 8500, Loss: -0.0481\n",
      "Epoch 8600, Loss: -0.0481\n",
      "Epoch 8700, Loss: -0.0480\n",
      "Epoch 8800, Loss: -0.0480\n",
      "Epoch 8900, Loss: -0.0480\n",
      "Epoch 9000, Loss: -0.0480\n",
      "Epoch 9100, Loss: -0.0481\n",
      "Epoch 9200, Loss: -0.0481\n",
      "Epoch 9300, Loss: -0.0481\n",
      "Epoch 9400, Loss: -0.0481\n",
      "Epoch 9500, Loss: -0.0481\n",
      "Epoch 9600, Loss: -0.0482\n",
      "Epoch 9700, Loss: -0.0482\n",
      "Epoch 9800, Loss: -0.0482\n",
      "Epoch 9900, Loss: -0.0483\n",
      "Epoch 10000, Loss: -0.0484\n",
      "Epoch 10100, Loss: -0.0484\n",
      "Epoch 10200, Loss: -0.0485\n",
      "Epoch 10300, Loss: -0.0486\n",
      "Epoch 10400, Loss: -0.0486\n",
      "Epoch 10500, Loss: -0.0487\n",
      "Epoch 10600, Loss: -0.0488\n",
      "Epoch 10700, Loss: -0.0488\n",
      "Epoch 10800, Loss: -0.0489\n",
      "Epoch 10900, Loss: -0.0490\n",
      "Epoch 11000, Loss: -0.0490\n",
      "Epoch 11100, Loss: -0.0491\n",
      "Epoch 11200, Loss: -0.0492\n",
      "Epoch 11300, Loss: -0.0492\n",
      "Epoch 11400, Loss: -0.0492\n",
      "Epoch 11500, Loss: -0.0493\n",
      "Epoch 11600, Loss: -0.0493\n",
      "Epoch 11700, Loss: -0.0494\n",
      "Epoch 11800, Loss: -0.0494\n",
      "Epoch 11900, Loss: -0.0494\n",
      "Epoch 12000, Loss: -0.0494\n",
      "Epoch 12100, Loss: -0.0495\n",
      "Epoch 12200, Loss: -0.0495\n",
      "Epoch 12300, Loss: -0.0495\n",
      "Epoch 12400, Loss: -0.0495\n",
      "Epoch 12500, Loss: -0.0495\n",
      "Epoch 12600, Loss: -0.0496\n",
      "Epoch 12700, Loss: -0.0496\n",
      "Epoch 12800, Loss: -0.0496\n",
      "Epoch 12900, Loss: -0.0496\n",
      "Epoch 13000, Loss: -0.0496\n",
      "Epoch 13100, Loss: -0.0496\n",
      "Epoch 13200, Loss: -0.0496\n",
      "Epoch 13300, Loss: -0.0496\n",
      "Epoch 13400, Loss: -0.0496\n",
      "Epoch 13500, Loss: -0.0496\n",
      "Epoch 13600, Loss: -0.0496\n",
      "Epoch 13700, Loss: -0.0496\n",
      "Epoch 13800, Loss: -0.0497\n",
      "Epoch 13900, Loss: -0.0497\n",
      "Epoch 14000, Loss: -0.0497\n",
      "Epoch 14100, Loss: -0.0497\n",
      "Epoch 14200, Loss: -0.0497\n",
      "Epoch 14300, Loss: -0.0497\n",
      "Epoch 14400, Loss: -0.0497\n",
      "Epoch 14500, Loss: -0.0497\n",
      "Epoch 14600, Loss: -0.0497\n",
      "Epoch 14700, Loss: -0.0497\n",
      "Epoch 14800, Loss: -0.0497\n",
      "Epoch 14900, Loss: -0.0497\n",
      "Epoch 15000, Loss: -0.0496\n",
      "Epoch 15100, Loss: -0.0496\n",
      "Epoch 15200, Loss: -0.0496\n",
      "Epoch 15300, Loss: -0.0496\n",
      "Epoch 15400, Loss: -0.0496\n",
      "Epoch 15500, Loss: -0.0496\n",
      "Epoch 15600, Loss: -0.0496\n",
      "Epoch 15700, Loss: -0.0496\n",
      "Epoch 15800, Loss: -0.0496\n",
      "Epoch 15900, Loss: -0.0496\n",
      "Epoch 16000, Loss: -0.0496\n",
      "Epoch 16100, Loss: -0.0496\n",
      "Epoch 16200, Loss: -0.0496\n",
      "Epoch 16300, Loss: -0.0496\n",
      "Epoch 16400, Loss: -0.0496\n",
      "Epoch 16500, Loss: -0.0496\n",
      "Epoch 16600, Loss: -0.0496\n",
      "Epoch 16700, Loss: -0.0496\n",
      "Epoch 16800, Loss: -0.0496\n",
      "Epoch 16900, Loss: -0.0496\n",
      "Epoch 17000, Loss: -0.0496\n",
      "Epoch 17100, Loss: -0.0496\n",
      "Epoch 17200, Loss: -0.0496\n",
      "Epoch 17300, Loss: -0.0496\n",
      "Epoch 17400, Loss: -0.0496\n",
      "Epoch 17500, Loss: -0.0496\n",
      "Epoch 17600, Loss: -0.0496\n",
      "Epoch 17700, Loss: -0.0496\n",
      "Epoch 17800, Loss: -0.0496\n",
      "Epoch 17900, Loss: -0.0495\n",
      "Epoch 18000, Loss: -0.0495\n",
      "Epoch 18100, Loss: -0.0495\n",
      "Epoch 18200, Loss: -0.0495\n",
      "Epoch 18300, Loss: -0.0495\n",
      "Epoch 18400, Loss: -0.0495\n",
      "Epoch 18500, Loss: -0.0495\n",
      "Epoch 18600, Loss: -0.0495\n",
      "Epoch 18700, Loss: -0.0495\n",
      "Epoch 18800, Loss: -0.0495\n",
      "Epoch 18900, Loss: -0.0495\n",
      "Epoch 19000, Loss: -0.0495\n",
      "Epoch 19100, Loss: -0.0495\n",
      "Epoch 19200, Loss: -0.0495\n",
      "Epoch 19300, Loss: -0.0495\n",
      "Epoch 19400, Loss: -0.0495\n",
      "Epoch 19500, Loss: -0.0495\n",
      "Epoch 19600, Loss: -0.0495\n",
      "Epoch 19700, Loss: -0.0495\n",
      "Epoch 19800, Loss: -0.0495\n",
      "Epoch 19900, Loss: -0.0495\n",
      "Epoch 20000, Loss: -0.0495\n",
      "Epoch 20100, Loss: -0.0495\n",
      "Epoch 20200, Loss: -0.0495\n",
      "Epoch 20300, Loss: -0.0495\n",
      "Epoch 20400, Loss: -0.0495\n",
      "Epoch 20500, Loss: -0.0495\n",
      "Epoch 20600, Loss: -0.0495\n",
      "Epoch 20700, Loss: -0.0495\n",
      "Epoch 20800, Loss: -0.0495\n",
      "Epoch 20900, Loss: -0.0494\n",
      "Epoch 21000, Loss: -0.0494\n",
      "Epoch 21100, Loss: -0.0494\n",
      "Epoch 21200, Loss: -0.0494\n",
      "Epoch 21300, Loss: -0.0494\n",
      "Epoch 21400, Loss: -0.0494\n",
      "Epoch 21500, Loss: -0.0494\n",
      "Epoch 21600, Loss: -0.0494\n",
      "Epoch 21700, Loss: -0.0494\n",
      "Epoch 21800, Loss: -0.0494\n",
      "Epoch 21900, Loss: -0.0494\n",
      "Epoch 22000, Loss: -0.0494\n",
      "Epoch 22100, Loss: -0.0494\n",
      "Epoch 22200, Loss: -0.0494\n",
      "Epoch 22300, Loss: -0.0494\n",
      "Epoch 22400, Loss: -0.0494\n",
      "Epoch 22500, Loss: -0.0494\n",
      "Epoch 22600, Loss: -0.0494\n",
      "Epoch 22700, Loss: -0.0494\n",
      "Epoch 22800, Loss: -0.0494\n",
      "Epoch 22900, Loss: -0.0494\n",
      "Epoch 23000, Loss: -0.0494\n",
      "Epoch 23100, Loss: -0.0494\n",
      "Epoch 23200, Loss: -0.0494\n",
      "Epoch 23300, Loss: -0.0494\n",
      "Epoch 23400, Loss: -0.0494\n",
      "Epoch 23500, Loss: -0.0494\n",
      "Epoch 23600, Loss: -0.0494\n",
      "Epoch 23700, Loss: -0.0494\n",
      "Epoch 23800, Loss: -0.0494\n",
      "Epoch 23900, Loss: -0.0494\n",
      "Epoch 24000, Loss: -0.0494\n",
      "Epoch 24100, Loss: -0.0494\n",
      "Epoch 24200, Loss: -0.0494\n",
      "Epoch 24300, Loss: -0.0494\n",
      "Epoch 24400, Loss: -0.0494\n",
      "Epoch 24500, Loss: -0.0494\n",
      "Epoch 24600, Loss: -0.0494\n",
      "Epoch 24700, Loss: -0.0494\n",
      "Epoch 24800, Loss: -0.0494\n",
      "Epoch 24900, Loss: -0.0494\n",
      "Epoch 25000, Loss: -0.0494\n",
      "Epoch 25100, Loss: -0.0494\n",
      "Epoch 25200, Loss: -0.0494\n",
      "Epoch 25300, Loss: -0.0494\n",
      "Epoch 25400, Loss: -0.0493\n",
      "Epoch 25500, Loss: -0.0493\n",
      "Epoch 25600, Loss: -0.0493\n",
      "Epoch 25700, Loss: -0.0493\n",
      "Epoch 25800, Loss: -0.0493\n",
      "Epoch 25900, Loss: -0.0493\n",
      "Epoch 26000, Loss: -0.0493\n",
      "Epoch 26100, Loss: -0.0493\n",
      "Epoch 26200, Loss: -0.0493\n",
      "Epoch 26300, Loss: -0.0493\n",
      "Epoch 26400, Loss: -0.0493\n",
      "Epoch 26500, Loss: -0.0493\n",
      "Epoch 26600, Loss: -0.0493\n",
      "Epoch 26700, Loss: -0.0493\n",
      "Epoch 26800, Loss: -0.0493\n",
      "Epoch 26900, Loss: -0.0493\n",
      "Epoch 27000, Loss: -0.0493\n",
      "Epoch 27100, Loss: -0.0493\n",
      "Epoch 27200, Loss: -0.0493\n",
      "Epoch 27300, Loss: -0.0493\n",
      "Epoch 27400, Loss: -0.0493\n",
      "Epoch 27500, Loss: -0.0493\n",
      "Epoch 27600, Loss: -0.0493\n",
      "Epoch 27700, Loss: -0.0493\n",
      "Epoch 27800, Loss: -0.0493\n",
      "Epoch 27900, Loss: -0.0493\n",
      "Epoch 28000, Loss: -0.0493\n",
      "Epoch 28100, Loss: -0.0493\n",
      "Epoch 28200, Loss: -0.0493\n",
      "Epoch 28300, Loss: -0.0493\n",
      "Epoch 28400, Loss: -0.0493\n",
      "Epoch 28500, Loss: -0.0493\n",
      "Epoch 28600, Loss: -0.0493\n",
      "Epoch 28700, Loss: -0.0493\n",
      "Epoch 28800, Loss: -0.0493\n",
      "Epoch 28900, Loss: -0.0493\n",
      "Epoch 29000, Loss: -0.0493\n",
      "Epoch 29100, Loss: -0.0493\n",
      "Epoch 29200, Loss: -0.0493\n",
      "Epoch 29300, Loss: -0.0493\n",
      "Epoch 29400, Loss: -0.0493\n",
      "Epoch 29500, Loss: -0.0493\n",
      "Epoch 29600, Loss: -0.0493\n",
      "Epoch 29700, Loss: -0.0493\n",
      "Epoch 29800, Loss: -0.0493\n",
      "Epoch 29900, Loss: -0.0493\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "weights, bias = train(X, y, input_size, output_size, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:\n",
      "[[3.02518597e-05 1.31612343e-05 8.06829534e-09]\n",
      " [1.02211656e-05 1.63787339e-10 1.08499694e-08]\n",
      " [4.10442173e-08 5.73587078e-07 5.08031308e-04]\n",
      " ...\n",
      " [8.99696629e-12 4.38920823e-08 5.70991155e-10]\n",
      " [4.84776924e-12 9.86409933e-01 1.99757672e-04]\n",
      " [2.25590526e-13 5.16016814e-19 5.95498256e-09]]\n",
      "Salidas reales:\n",
      "[[-0.66390084  1.34145628 -0.71274119]\n",
      " [ 1.50624903 -0.74545851 -0.71274119]\n",
      " [-0.66390084  1.34145628 -0.71274119]\n",
      " ...\n",
      " [-0.66390084  1.34145628 -0.71274119]\n",
      " [-0.66390084  1.34145628 -0.71274119]\n",
      " [-0.66390084  1.34145628 -0.71274119]]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X, weights, bias)\n",
    "print(\"Predicciones:\")\n",
    "print(predictions)\n",
    "\n",
    "# Salidas reales para comparación\n",
    "print(\"Salidas reales:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9684802423180792"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean((y - predictions) ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
